# Neural Machine Translation (from German to English)

## 1. Introduction

In this assignment, initially we are given a `seq2seq` neural machine translation (NMT) network with broken attention mechanism.

Our tasks are:

- Correctly implement attention mechanism for the `seq2seq` network;
- Implement `beam search` as a better decoding strategy;
- Implement any techniques to further improve the `BLEU` scores.

Please refer to [neuralmt.ipynb](neuralmt.ipynb) to check out our detailed explanation of the code design and the results generated by our code. Our best translation outcome (measured by `BLEU` scores) is at: `output > dev.out` and `output > test.out`. For a high level summary of our methods, results, and conclusions, please refer to our [report](report.pdf).

**Topics:** _Natural Language Processing_, _Neural Machine Translation_, _seq2seq Models_, _Attention Mechanism_

**Skills:** _Pytorch_, _Python_, _Jupyter Lab_

## 2. How to run the code



## 3. Results
